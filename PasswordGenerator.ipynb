{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passwort Generator\n",
    "Das Projekt hat sich die Erstellung eines Passwort-Generators als Ziel gesetzt. Dabei sollen die zu erstellenden Passwörter möglichst denen eines Menschen ähneln. \n",
    "Zur Realisierung wurde die RNN- Architektur verwendet. Diese Recurrent Neural Networks ermöglichen es, Voraussagen mittels eines Kontext zu treffen, der durch frühere Inputs entstanden ist. Das Netzwerk verfügt sozusagen über ein Gedächtnis. In der Umsetzung geschieht dies durch die Kombination des Hidden-Layern aus der vorherigen Sequenz mit den Hidden-Layern aus der aktuellen Sequenz. Die vorherigen Hidden-Layer haben damit Einfluß auf den Output der nächsten Sequenz. Dieser Algorithmus wird in einer Schleife abgebildet, bis sämtliche Inputs verarbeitet wurden und der Kontext ersichtlich ist.\n",
    "Klarer wird dies mit den nachfolgenden Formeln, mit denen das Netzwerk trainiert wird:\n",
    "\n",
    "\\begin{align}\n",
    "\\ h_t  = f(W^{hh}h_t-1 + W^{hx} + x_t \\\\\n",
    "\\ y_t  = softmax(W^Sh_t) \\\\\n",
    "\\ J^t(\\theta)  =\\sum_{i=1}^{[V]} (y_{ti}\\log(y_{ti}))\n",
    "\\end{align}\n",
    "\n",
    "Die erste Formel ist dafür da, sich an die Hidden-Layer des vorherigen Durchlaufs zu \"erinnern\". Dabei wird durch h-1 auf den vorherigen Hidden-Layer zugegriffen. Dies wird kombiniert mit dem aktuellen x, auch wird anschließend eine Akivierungsfunktion durchgeführt, am gebräuchlisten sind hierbei der Tangens hyperbolicus oder die Sigmoid-Funktion.\n",
    "Die zweite Formel kümmert sich um die Voraussage des nächsten Ergebnisses in Form von einer Wahrscheinlichkeitsverteilung. \n",
    "Zum Schluss wird in der dritten Formel mittels der Cross-Entropy-Loss-Funktion der Fehler zwischen dem Input und dem Output berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import wget # to download passwordlist\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auslesen der Passworddatei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in letters\n",
    "    )\n",
    "\n",
    "def readPasswords(filename):\n",
    "    passwords = []\n",
    "    with open(filename, 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "        for line in f:\n",
    "            if len(line) > 1:\n",
    "                passwords.append(line)\n",
    "    passw = [unicodeToAscii(password) for password in passwords]\n",
    "    print('successful read passwords')\n",
    "    return passw\n",
    "\n",
    "def charToIndex(char):\n",
    "    return letters.find(char)\n",
    "\n",
    "def passwordToTensor(name):\n",
    "    ret = torch.zeros(len(name), 1, len_letters)\n",
    "    for i, char in enumerate(name):\n",
    "        ret[i][0][charToIndex(char)] = 1\n",
    "    return ret\n",
    "\n",
    "def targetToTensor(password):\n",
    "    indizes = [letters.find(password[i]) for i in range(1,len(password))]\n",
    "    indizes.append(len_letters - 1) #EOS\n",
    "    return torch.LongTensor(indizes)\n",
    "                                                        \n",
    "    \n",
    "letters = string.ascii_letters + string.digits + string.punctuation\n",
    "len_letters = len(letters) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download der Passwortliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download passwordlist:\n",
      "100% [......................................................................] 139921497 / 139921497successful read passwords\n"
     ]
    }
   ],
   "source": [
    "filename = 'rockyou.txt'\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    print('passwordlist exists')\n",
    "    passwords = readPasswords(filename)\n",
    "else:\n",
    "    print('download passwordlist:')\n",
    "    #download list\n",
    "    wget.download('https://www.scrapmaker.com/data/wordlists/dictionaries/rockyou.txt')\n",
    "    print('\\n')\n",
    "    passwords = readPasswords(filename)\n",
    "\n",
    "#entfernen von leeren Zeilen\n",
    "passwords = [passw for passw in passwords if passw != '']\n",
    "for passw in passwords:\n",
    "    if len(passw)<1:\n",
    "        print('pass:-'+passw+'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktivierungsfunktionen\n",
    "    nn.LogSoftmax() - \n",
    "    nn.LeakyReLU() - \n",
    "    nn.LogSigmoid() -\n",
    "    nn.Tanh() - \n",
    "## Generatorklasse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "class PasswordGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PasswordGenerator, self).__init__()\n",
    "        self.hidden = hidden_size\n",
    "        self.input2hidden = nn.Linear(input_size + hidden_size, hidden_size, bias=True)\n",
    "        self.input2output = nn.Linear(input_size + hidden_size, output_size, bias=True)\n",
    "        self.output2output = nn.Linear(hidden_size +  output_size, output_size, bias=True)        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.LogSigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined_input = torch.cat((input, hidden), dim=1)\n",
    "        hidden = self.input2hidden(combined_input)\n",
    "        output = self.input2output(combined_input)\n",
    "        combined_output = torch.cat((hidden, output), dim=1)\n",
    "        output = self. output2output(combined_output)        \n",
    "        output = self.dropout(output)\n",
    "        #output = self.softmax(output)\n",
    "        \n",
    "        #output = self.sigmoid(output)\n",
    "        output = self.relu(output)\n",
    "        #output = self.tanh(output)\n",
    "        \n",
    "        return hidden, output\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Funktionen\n",
    "    nn.BCELoss() - Binary Cross Entropy\n",
    "    nn.BCEWithLogitsLoss() - This loss combines a Sigmoid layer and the BCELoss in one single class\n",
    "    nn.NLLLoss() - negative log likelihood loss\n",
    "    nn.CrossEntropyLoss() - combines nn.LogSoftmax() and nn.NLLLoss() in one single class\n",
    "    \n",
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PasswordGenerator(len_letters, len_letters, len_letters)\n",
    "loss_fn = nn.CrossEntropyLoss() #define Loss Function\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def trainPasswords(input, target):\n",
    "    target.unsqueeze_(-1)\n",
    "    hidden = model.initHidden()\n",
    "    model.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "    loss = 0\n",
    "    for i in range(input.size()[0]):\n",
    "        hidden, output = model(input[i], hidden)\n",
    "        l = loss_fn(output, target[i]) # Compute the loss\n",
    "        loss += l\n",
    "    loss.requires_grad_(True) # The autograd package provides automatic differentiation for all operations on Tensors\n",
    "    loss.backward()\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.add(-learning_rate, p.grad.data)\n",
    "        \n",
    "    return output, loss.item() / input.size(0)\n",
    "\n",
    "def train(trainrounds):\n",
    "    total_loss = 0\n",
    "    plots = []\n",
    "    plot_every = 100\n",
    "    progress = 0\n",
    "    c = 0\n",
    "    \n",
    "    for j in range(0, trainrounds):\n",
    "    #for j in range(len(passwords)):\n",
    "            #password = passwords[j]\n",
    "            password = random.choice(passwords)\n",
    "            #print(password)\n",
    "            input = passwordToTensor(password)\n",
    "            target = targetToTensor(password)\n",
    "            output, loss = trainPasswords(input, target)\n",
    "            total_loss += loss\n",
    "            \n",
    "            progress = j / trainrounds * 100\n",
    "            if (c < round(progress) and round(progress) % 5 == 0) or j == 1:\n",
    "                c = round(progress)\n",
    "                print(round(progress), '% made. Loss: ', loss)\n",
    "            if j % plot_every == 0:\n",
    "                plots.append(total_loss / plot_every)\n",
    "                total_loss = 0\n",
    "                torch.save(model, filename)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Password:  xrzO1yP9HrP\n",
      "0 % made. Loss:  4.5396333421979636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type PasswordGenerator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 % made. Loss:  4.424862452915737\n",
      "10 % made. Loss:  4.291022981916155\n",
      "15 % made. Loss:  4.2718353271484375\n",
      "20 % made. Loss:  4.103475130521334\n",
      "25 % made. Loss:  3.8018314838409424\n",
      "30 % made. Loss:  3.9408336215549045\n",
      "35 % made. Loss:  3.9388067072088067\n",
      "40 % made. Loss:  4.015130678812663\n",
      "45 % made. Loss:  4.6246234348842075\n",
      "50 % made. Loss:  5.009593418666294\n",
      "55 % made. Loss:  4.332085745675223\n",
      "60 % made. Loss:  4.14572994525616\n",
      "65 % made. Loss:  4.657740592956543\n"
     ]
    }
   ],
   "source": [
    "max_chars = 10 # max 10 chars for password\n",
    "\n",
    "def sample(start_letter='a'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        input = passwordToTensor(start_letter)\n",
    "        hidden = model.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_chars):\n",
    "            output, hidden = model(input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == len_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = letters[topi]\n",
    "                output_name += letter\n",
    "            input = passwordToTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "#before train\n",
    "random_start_char = random.choice(letters)\n",
    "gen_password = sample(random_start_char)\n",
    "print('Sampled Password: ', gen_password)\n",
    "\n",
    "#train\n",
    "#train(range(len(passwords)))\n",
    "train(10000)\n",
    "\n",
    "#after train\n",
    "gen_password = sample(random_start_char)\n",
    "print('Sampled Password: ', gen_password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
